{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457b634f",
   "metadata": {},
   "source": [
    "# Audio Tracks Processing and Dataset Creation\n",
    "For convenience, all audio files from the GTZAN dataset, originally divided by genre into separate folders, have been placed together in a single directory called \"GTZAN_30s\". In this notebook, the 30s tracks are split into 3s pieces. Then, spectral and other music-specific features are extracted from the tracks and the final dataset is created, containing tracks features classified by their musical genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64908f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eee114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30s .wav files are split into 3s .wav files\n",
    "\n",
    "input_folder = Path(r\"..\\dataset\\GTZAN_30s\")\n",
    "output_folder = Path(r\"..\\dataset\\GTZAN_3s\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "chunk_length_ms = 3 * 1000  # 3s\n",
    "\n",
    "for wav_file in tqdm(sorted(input_folder.glob(\"*.wav\"))):\n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "    file_name = wav_file.stem \n",
    "    \n",
    "    num_chunks = len(audio) // chunk_length_ms\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_ms = i * chunk_length_ms\n",
    "        end_ms = start_ms + chunk_length_ms\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        \n",
    "        chunk_name = f\"{file_name}_{i:02d}.wav\"\n",
    "        chunk.export(output_folder / chunk_name, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio tracks analysis and feature extraction\n",
    "\n",
    "def extract_features(filepath):\n",
    "    # 22.05 kHz sampling\n",
    "    y, sr = librosa.load(filepath, sr=22050)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Mel Frequency Cepstral Coefficients\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=15)\n",
    "    for i in range(mfcc.shape[0]):\n",
    "        features[f'mfcc_{i+1}_mean'] = np.mean(mfcc[i])\n",
    "        features[f'mfcc_{i+1}_std'] = np.std(mfcc[i])\n",
    "\n",
    "    # Chroma\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    for i in range(chroma.shape[0]):\n",
    "        features[f'chroma_{i+1}_mean'] = np.mean(chroma[i])\n",
    "\n",
    "    # Spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    for i in range(contrast.shape[0]):\n",
    "        features[f'contrast_{i+1}_mean'] = np.mean(contrast[i])\n",
    "\n",
    "    # Other spectral features\n",
    "    features['spec_centroid_mean'] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    features['spec_bandwidth_mean'] = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    features['spec_rolloff_mean'] = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    features['zcr_mean'] = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    features['rms_mean'] = np.mean(librosa.feature.rms(y=y))\n",
    "\n",
    "    # Tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features['tempo'] = tempo\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224d4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1090e510d2d42e3ae0afd82967d4e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing audio files:   0%|          | 0/9991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['mfcc_1_mean', 'mfcc_1_std', 'mfcc_2_mean', 'mfcc_2_std', 'mfcc_3_mean',\n",
       "       'mfcc_3_std', 'mfcc_4_mean', 'mfcc_4_std', 'mfcc_5_mean', 'mfcc_5_std',\n",
       "       'mfcc_6_mean', 'mfcc_6_std', 'mfcc_7_mean', 'mfcc_7_std', 'mfcc_8_mean',\n",
       "       'mfcc_8_std', 'mfcc_9_mean', 'mfcc_9_std', 'mfcc_10_mean',\n",
       "       'mfcc_10_std', 'mfcc_11_mean', 'mfcc_11_std', 'mfcc_12_mean',\n",
       "       'mfcc_12_std', 'mfcc_13_mean', 'mfcc_13_std', 'mfcc_14_mean',\n",
       "       'mfcc_14_std', 'mfcc_15_mean', 'mfcc_15_std', 'chroma_1_mean',\n",
       "       'chroma_2_mean', 'chroma_3_mean', 'chroma_4_mean', 'chroma_5_mean',\n",
       "       'chroma_6_mean', 'chroma_7_mean', 'chroma_8_mean', 'chroma_9_mean',\n",
       "       'chroma_10_mean', 'chroma_11_mean', 'chroma_12_mean', 'contrast_1_mean',\n",
       "       'contrast_2_mean', 'contrast_3_mean', 'contrast_4_mean',\n",
       "       'contrast_5_mean', 'contrast_6_mean', 'contrast_7_mean',\n",
       "       'spec_centroid_mean', 'spec_bandwidth_mean', 'spec_rolloff_mean',\n",
       "       'zcr_mean', 'rms_mean', 'tempo', 'genre'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the extract_features function to create the dataset\n",
    "\n",
    "audio_dir = \"../dataset/GTZAN_3s\"\n",
    "dataset = []\n",
    "\n",
    "for filename in tqdm(os.listdir(audio_dir), desc=\"Processing audio files\"):\n",
    "    if filename.lower().endswith(\".wav\"):\n",
    "        filepath = os.path.join(audio_dir, filename)\n",
    "        \n",
    "        # Extract genre from filename\n",
    "        genre = filename.split('.')[0]\n",
    "        \n",
    "        try:\n",
    "            features = extract_features(filepath)\n",
    "            features['genre'] = genre\n",
    "            \n",
    "            dataset.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(dataset)   \n",
    "\n",
    "df['tempo'] = df['tempo'].astype(float)\n",
    "\n",
    "df.to_csv(\"../df/project_features.csv\", index=False)\n",
    "\n",
    "df.columns   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
